{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import signal\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, GRU, Embedding, Dense, Activation, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "\n",
    "outpath = \"../../../plots/temperatures\"\n",
    "inpath = \"../../../\"\n",
    "\n",
    "currentfile = \"Imitator_2_2400.csv\"\n",
    "\n",
    "# Read from file\n",
    "strdatatype = np.dtype([('N', np.int_, (2,)), ('Time_Count', np.int_ ), ('Mode', np.int_ ),\n",
    "                        ('T', np.float_, (10,)), ('S', np.bool_, (10,)), ('System_State', np.bool_ )])\n",
    "N, Time_Count, Mode, T, S, System_State = np.loadtxt(path.join(inpath, currentfile), \n",
    "                                                     unpack=True, delimiter=';', skiprows=1, dtype=strdatatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_possible_model_temperature = 15.0\n",
    "min_possible_model_temperature = 70.0\n",
    "def scale_T(_T):\n",
    "    return (_T - min_possible_model_temperature) / (max_possible_model_temperature - min_possible_model_temperature)\n",
    "\n",
    "def unscale_T(_T):\n",
    "    return (_T) * (max_possible_model_temperature - min_possible_model_temperature) + min_possible_model_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputBlockId=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sT = scale_T(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = np.amin(np.abs(sT[:-2, :] - sT[1:-1, :])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1317509536489254e-06"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmintation -- 50000 slightly tuned copies of T\n",
    "agmntCount=50000\n",
    "agmntdT=np.zeros((agmntCount, np.size(sT[:,0]), np.size(sT[0,:])))\n",
    "agmntdT[0,:,:] = sT\n",
    "np.random.seed(0)\n",
    "mu, sigma = 0, delta*100\n",
    "for i in range(1, agmntCount):\n",
    "    agmntdT[i] = agmntdT[0] + np.random.normal(mu, sigma, (np.size(sT[:,0]), np.size(sT[0,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2401, 10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmntdT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictSteps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep dataset tail for validate prediction quality\n",
    "cutFromTail = 60\n",
    "#In order to have shifted and unshifted series with same shape\n",
    "t = cutFromTail + predictSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "inData = np.zeros((agmntCount, np.size(sT[:-t,0]), np.size(sT[0,:]) + 1))\n",
    "for i in range(0, agmntCount):\n",
    "    inData[i,:,0] = Mode[:-t] / np.amax(Mode[:-t])\n",
    "    inData[i,:,1:]= agmntdT[i,:-t,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2340, 11)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = np.expand_dims(agmntdT[:,predictSteps:-cutFromTail,outputBlockId], axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2340, 1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = len(inData[0,:,0])\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1872"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = int(train_split * num_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "468"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test = num_data - num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData_train = inData[:, 0:num_train, :]\n",
    "inData_test = inData[:, num_train:, :]\n",
    "len(inData_train[0,:,0]) + len(inData_test[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2340"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData_train = outData[:, 0:num_train, :]\n",
    "outData_test = outData[:, num_train:, :]\n",
    "len(outData_train[0,:,0]) + len(outData_test[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inData_signals = inData.shape[2]\n",
    "num_inData_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_outData_signals = outData.shape[2]\n",
    "num_outData_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 6068048109954712784\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3316711424\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 2987543824258985611\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 770, pci bus id: 0000:01:00.0, compute capability: 3.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        in_shape = (batch_size, sequence_length, num_inData_signals)\n",
    "        in_batch = np.zeros(shape=in_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        out_shape = (batch_size, sequence_length, num_outData_signals)\n",
    "        out_batch = np.zeros(shape=out_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            # This points somewhere into the augmented series range.\n",
    "            idaugmnt = np.random.randint(agmntCount)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            in_batch[i] = inData_train[idaugmnt, idx:idx+sequence_length,:]\n",
    "            out_batch[i] = outData_train[idaugmnt, idx:idx+sequence_length,:]\n",
    "        \n",
    "        yield (in_batch, out_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=batch_size,\n",
    "                            sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_batch, out_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 512, 11)\n",
      "(200, 512, 1)\n"
     ]
    }
   ],
   "source": [
    "print(in_batch.shape)\n",
    "print(out_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fddda8dab10>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 0   # First sequence in the batch.\n",
    "signal = 1  # First signal from the 21 input-signals.\n",
    "seq = in_batch[batch,predictSteps:predictSteps+50, signal]\n",
    "plt.scatter(np.arange(0, len(seq)), seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fddda00fe50>"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = out_batch[batch, 0:50, 0]\n",
    "plt.scatter(np.arange(0, len(seq)),seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(inData_test[0,:,:], axis=0),\n",
    "                   np.expand_dims(outData_test[0,:,:], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(144, return_sequences=True, input_shape=(None, num_inData_signals,)))\n",
    "model.add(LSTM(96, return_sequences=True))\n",
    "model.add(LSTM(48, return_sequences=True))\n",
    "model.add(LSTM(24, return_sequences=True))\n",
    "model.add(LSTM(3, return_sequences=True))\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = RMSprop(lr=1e-3)\n",
    "sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(learning_rate=1e-3), loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_28 (LSTM)               (None, None, 144)         89856     \n",
      "_________________________________________________________________\n",
      "lstm_29 (LSTM)               (None, None, 96)          92544     \n",
      "_________________________________________________________________\n",
      "lstm_30 (LSTM)               (None, None, 48)          27840     \n",
      "_________________________________________________________________\n",
      "lstm_31 (LSTM)               (None, None, 24)          7008      \n",
      "_________________________________________________________________\n",
      "lstm_32 (LSTM)               (None, None, 3)           336       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, None, 1)           4         \n",
      "=================================================================\n",
      "Total params: 217,588\n",
      "Trainable params: 217,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = str(outputBlockId)+'_checkpoint_test.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback_tensorboard = keras.callbacks.TensorBoard(log_dir=\"logdir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-4,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "            callback_checkpoint,\n",
    "            callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "50/50 [==============================] - 80s 2s/step - loss: 0.1445 - val_loss: 0.1216\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.12163, saving model to 0_checkpoint_test.keras\n",
      "Epoch 2/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.1207 - val_loss: 0.1171\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.12163 to 0.11710, saving model to 0_checkpoint_test.keras\n",
      "Epoch 3/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0962 - val_loss: 0.0823\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11710 to 0.08233, saving model to 0_checkpoint_test.keras\n",
      "Epoch 4/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0669 - val_loss: 0.0790\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.08233 to 0.07901, saving model to 0_checkpoint_test.keras\n",
      "Epoch 5/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0562 - val_loss: 0.0556\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.07901 to 0.05565, saving model to 0_checkpoint_test.keras\n",
      "Epoch 6/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0487 - val_loss: 0.0515\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05565 to 0.05147, saving model to 0_checkpoint_test.keras\n",
      "Epoch 7/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0437 - val_loss: 0.0453\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.05147 to 0.04526, saving model to 0_checkpoint_test.keras\n",
      "Epoch 8/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0405 - val_loss: 0.0412\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04526 to 0.04120, saving model to 0_checkpoint_test.keras\n",
      "Epoch 9/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0374 - val_loss: 0.0399\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04120 to 0.03992, saving model to 0_checkpoint_test.keras\n",
      "Epoch 10/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0353 - val_loss: 0.0384\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.03992 to 0.03836, saving model to 0_checkpoint_test.keras\n",
      "Epoch 11/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0378 - val_loss: 0.0417\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.03836\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 12/1000\n",
      "50/50 [==============================] - 72s 1s/step - loss: 0.0333 - val_loss: 0.0375\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03836 to 0.03752, saving model to 0_checkpoint_test.keras\n",
      "Epoch 13/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0326 - val_loss: 0.0373\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03752 to 0.03727, saving model to 0_checkpoint_test.keras\n",
      "Epoch 14/1000\n",
      "50/50 [==============================] - 73s 1s/step - loss: 0.0323 - val_loss: 0.0370\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03727 to 0.03704, saving model to 0_checkpoint_test.keras\n",
      "Epoch 15/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0320 - val_loss: 0.0369\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03704 to 0.03693, saving model to 0_checkpoint_test.keras\n",
      "Epoch 16/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0318 - val_loss: 0.0367\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03693 to 0.03673, saving model to 0_checkpoint_test.keras\n",
      "Epoch 17/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0316 - val_loss: 0.0365\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03673 to 0.03651, saving model to 0_checkpoint_test.keras\n",
      "Epoch 18/1000\n",
      "50/50 [==============================] - 74s 1s/step - loss: 0.0314 - val_loss: 0.0363\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03651 to 0.03633, saving model to 0_checkpoint_test.keras\n",
      "Epoch 19/1000\n",
      "50/50 [==============================] - 76s 2s/step - loss: 0.0312 - val_loss: 0.0361\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.03633 to 0.03614, saving model to 0_checkpoint_test.keras\n",
      "Epoch 20/1000\n",
      "50/50 [==============================] - 83s 2s/step - loss: 0.0311 - val_loss: 0.0360\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.03614 to 0.03601, saving model to 0_checkpoint_test.keras\n",
      "Epoch 21/1000\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0309 - val_loss: 0.0359\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.03601 to 0.03593, saving model to 0_checkpoint_test.keras\n",
      "\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 22/1000\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0307 - val_loss: 0.0358\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.03593 to 0.03581, saving model to 0_checkpoint_test.keras\n",
      "Epoch 23/1000\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0306 - val_loss: 0.0357\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.03581 to 0.03568, saving model to 0_checkpoint_test.keras\n",
      "Epoch 24/1000\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0304 - val_loss: 0.0356\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.03568 to 0.03558, saving model to 0_checkpoint_test.keras\n",
      "Epoch 25/1000\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0302 - val_loss: 0.0356\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.03558 to 0.03556, saving model to 0_checkpoint_test.keras\n",
      "Epoch 26/1000\n",
      "50/50 [==============================] - 82s 2s/step - loss: 0.0300 - val_loss: 0.0354\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.03556 to 0.03541, saving model to 0_checkpoint_test.keras\n",
      "Epoch 27/1000\n",
      "46/50 [==========================>...] - ETA: 6s - loss: 0.0297"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(generator=generator,\n",
    "                    epochs=1000,\n",
    "                    steps_per_epoch=50,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x=np.expand_dims(inData_test[0], axis=0),\n",
    "                        y=np.expand_dims(outData_test[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(start_idx, length=100, train=True):\n",
    "    \"\"\"\n",
    "    Plot the predicted and true output-signals.\n",
    "    \n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if train:\n",
    "        # Use training-data.\n",
    "        x = inData_train[0]\n",
    "        y_true = outData_train[0]\n",
    "    else:\n",
    "        # Use test-data.\n",
    "        x = inData_test[0]\n",
    "        y_true = outData_test[0]\n",
    "    \n",
    "    # End-index for the sequences.\n",
    "    end_idx = start_idx + length\n",
    "    \n",
    "    # Select the sequences from the given start-index and\n",
    "    # of the given length.\n",
    "    x = x[start_idx:end_idx]\n",
    "    y_true = y_true[start_idx:end_idx]\n",
    "    \n",
    "    # Input-signals for the model.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Use the model to predict the output-signals.\n",
    "    y_pred = model.predict(x)\n",
    "    print(shape(x))\n",
    "    print(shape(y_pred))\n",
    "        \n",
    "    # Get the output-signal predicted by the model.\n",
    "    signal_pred = y_pred\n",
    "        \n",
    "    # Get the true output-signal from the data-set.\n",
    "    signal_true = y_true\n",
    "    \n",
    "    # Make the plotting-canvas bigger.\n",
    "    plt.figure(figsize=(15,5))\n",
    "        \n",
    "    # Plot and compare the two signals.\n",
    "    plt.plot(signal_true, label='true')\n",
    "    plt.scatter(np.arange(0, len(signal_pred[0])), signal_pred[0], label='pred', color='r')\n",
    "\n",
    "        \n",
    "    # Plot labels etc.\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(start_idx=0, length=512, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performOfSamplePrediction(outOfSampleCount):\n",
    "    prediction = np.zeros(0)\n",
    "    sequence_length_for_predict = sequence_length\n",
    "    predictBase = np.zeros((1, sequence_length_for_predict, num_inData_signals))\n",
    "    Modes = Mode[-(sequence_length_for_predict + cutFromTail): -cutFromTail] / 4.0\n",
    "    predictBase[0,:,0] = Modes\n",
    "    predictBase[0,:,1:] = sT[-(sequence_length_for_predict + cutFromTail): -cutFromTail,:]\n",
    "    hiddenOutput = np.zeros((1, sequence_length_for_predict, num_outData_signals))\n",
    "    for step in range(0,outOfSampleCount, predictSteps):\n",
    "        hiddenOutput = model.predict(predictBase)\n",
    "        plt.figure(figsize=(10,1))\n",
    "        plt.plot(sT[-(sequence_length_for_predict + cutFromTail):,1+outputBlockId])\n",
    "        plt.scatter(np.arange(step, len(hiddenOutput[0])+step), hiddenOutput[0,:,0], color='r', marker='.')\n",
    "        tmpModes = Modes[0:predictSteps]\n",
    "        Modes[0:-predictSteps] = Modes[predictSteps:]\n",
    "        Modes[-predictSteps:0] = tmpModes\n",
    "        predictBase[0,:,0] = Modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performOfSamplePrediction(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
