{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import signal\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, GRU, Embedding\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "\n",
    "outpath = \"../../../plots/temperatures\"\n",
    "inpath = \"../../../\"\n",
    "\n",
    "currentfile = \"Imitator_2_2400.csv\"\n",
    "\n",
    "# Read from file\n",
    "strdatatype = np.dtype([('N', np.int_, (2,)), ('Time_Count', np.int_ ), ('Mode', np.int_ ),\n",
    "                        ('T', np.float_, (10,)), ('S', np.bool_, (10,)), ('System_State', np.bool_ )])\n",
    "N, Time_Count, Mode, T, S, System_State = np.loadtxt(path.join(inpath, currentfile), \n",
    "                                                     unpack=True, delimiter=';', skiprows=1, dtype=strdatatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_possible_model_temperature = 15.0\n",
    "min_possible_model_temperature = 70.0\n",
    "def scale_T(_T):\n",
    "    return (_T - min_possible_model_temperature) / (max_possible_model_temperature - min_possible_model_temperature)\n",
    "\n",
    "def unscale_T(_T):\n",
    "    return (_T) * (max_possible_model_temperature - min_possible_model_temperature) + min_possible_model_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 18.40911018644466\n",
      "Max: 65.14203288058243\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(T))\n",
    "print(\"Max:\", np.max(T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.75318031, 39.16584902, 43.56690816, 43.06170964, 43.96788118,\n",
       "       46.17686177, 33.76846876, 44.39839526, 46.16541138, 51.17311   ])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44085127, 0.56062093, 0.48060167, 0.4897871 , 0.47331125,\n",
       "       0.43314797, 0.65875511, 0.46548372, 0.43335616, 0.34230709])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = scale_T(T[1,:])\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([45.75318031, 39.16584902, 43.56690816, 43.06170964, 43.96788118,\n",
       "       46.17686177, 33.76846876, 44.39839526, 46.16541138, 51.17311   ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unscale_T(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sT = scale_T(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44085127, 0.56062093, 0.48060167, 0.4897871 , 0.47331125,\n",
       "       0.43314797, 0.65875511, 0.46548372, 0.43335616, 0.34230709])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sT[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0883266748985012\n",
      "Max: 0.9380161784282788\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(sT))\n",
    "print(\"Max:\", np.max(sT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = np.amin(np.abs(sT[:-2, :] - sT[1:-1, :])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.1317509536489254e-06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmintation -- 150 slightly tuned copies of T\n",
    "agmntCount=1000\n",
    "agmntdT=np.zeros((agmntCount, np.size(sT[:,0]), np.size(sT[0,:])))\n",
    "agmntdT[0,:,:] = sT\n",
    "np.random.seed(0)\n",
    "mu, sigma = 0, delta*2.0\n",
    "for i in range(1, agmntCount):\n",
    "    agmntdT[i] = agmntdT[0] + np.random.normal(mu, sigma, (np.size(sT[:,0]), np.size(sT[0,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54021667, 0.65577633, 0.550259  , ..., 0.53329114, 0.53525912,\n",
       "        0.42799849],\n",
       "       [0.44085127, 0.56062093, 0.48060167, ..., 0.46548372, 0.43335616,\n",
       "        0.34230709],\n",
       "       [0.40730998, 0.52266703, 0.46367789, ..., 0.42774825, 0.41820337,\n",
       "        0.32762735],\n",
       "       ...,\n",
       "       [0.72793045, 0.63309985, 0.72434066, ..., 0.55001523, 0.59737163,\n",
       "        0.6965634 ],\n",
       "       [0.58471149, 0.5366876 , 0.5562961 , ..., 0.46114309, 0.47338423,\n",
       "        0.55688069],\n",
       "       [0.48766345, 0.446996  , 0.47673323, ..., 0.3744143 , 0.4029212 ,\n",
       "        0.48163992]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmntdT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.54022419, 0.65577804, 0.55026317, ..., 0.53329049, 0.53525868,\n",
       "        0.42800024],\n",
       "       [0.44085188, 0.56062713, 0.48060491, ..., 0.46548285, 0.43335749,\n",
       "        0.34230345],\n",
       "       [0.40729909, 0.52266982, 0.46368158, ..., 0.42774745, 0.4182099 ,\n",
       "        0.32763361],\n",
       "       ...,\n",
       "       [0.72792989, 0.63310071, 0.72433755, ..., 0.55001222, 0.59737012,\n",
       "        0.69656378],\n",
       "       [0.58470965, 0.53668228, 0.55629823, ..., 0.46114281, 0.47338859,\n",
       "        0.55687834],\n",
       "       [0.48766201, 0.44700272, 0.47673022, ..., 0.37441333, 0.4029244 ,\n",
       "        0.48164609]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmntdT[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2401, 10)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmntdT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictSteps = 20\n",
    "outputBlockId=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep dataset tail for validate prediction quality\n",
    "cutFromTail = 60\n",
    "#In order to have shifted and unshifted series with same shape\n",
    "t = cutFromTail + predictSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inData = np.zeros((agmntCount, np.size(sT[:-t,0]), np.size(sT[0,:]) + 1))\n",
    "for i in range(0, agmntCount):\n",
    "    inData[i,:,0] = Mode[:-t] / np.amax(Mode[:-t])\n",
    "    inData[i,:,1:]= agmntdT[i,:-t,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2321, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = np.expand_dims(agmntdT[:,predictSteps:-cutFromTail,outputBlockId], axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2321, 1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25      , 0.3582925 , 0.45176785, 0.35526583, 0.37376724,\n",
       "        0.29364176, 0.41655529, 0.41365044, 0.3941109 , 0.33955558,\n",
       "        0.40022814],\n",
       "       [0.5       , 0.34103498, 0.46969007, 0.3541308 , 0.37370865,\n",
       "        0.28430406, 0.41291223, 0.42029673, 0.39641978, 0.34164354,\n",
       "        0.4294365 ],\n",
       "       [0.        , 0.38792436, 0.52296676, 0.40454692, 0.42770222,\n",
       "        0.31860177, 0.43425302, 0.44343857, 0.42659087, 0.37203441,\n",
       "        0.47657331],\n",
       "       [0.75      , 0.36313741, 0.50552709, 0.37511916, 0.40091152,\n",
       "        0.30789115, 0.424267  , 0.40758046, 0.40021304, 0.3454241 ,\n",
       "        0.52565191],\n",
       "       [0.25      , 0.39871481, 0.50607118, 0.38205206, 0.42062058,\n",
       "        0.32690483, 0.44832612, 0.43612788, 0.41930769, 0.36022782,\n",
       "        0.57318826]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData[5, predictSteps:predictSteps+5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3582925 , 0.34103498, 0.38792436, 0.36313741, 0.39871481])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData[5,0:5,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2321"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = len(inData[0,:,0])\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.73"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1694"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = int(train_split * num_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "627"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test = num_data - num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2321"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData_train = inData[:, 0:num_train, :]\n",
    "inData_test = inData[:, num_train:, :]\n",
    "len(inData_train[0,:,0]) + len(inData_test[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2321"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData_train = outData[:, 0:num_train, :]\n",
    "outData_test = outData[:, num_train:, :]\n",
    "len(outData_train[0,:,0]) + len(outData_test[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inData_signals = inData.shape[2]\n",
    "num_inData_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_outData_signals = outData.shape[2]\n",
    "num_outData_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.0\n",
      "Max: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(inData_train))\n",
    "print(\"Max:\", np.max(inData_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 0.09171084239445997\n",
      "Max: 0.9380287359657481\n"
     ]
    }
   ],
   "source": [
    "print(\"Min:\", np.min(inData_train[:,:,1:]))\n",
    "print(\"Max:\", np.max(inData_train[:,:,1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 1694, 11)\n",
      "(1000, 1694, 1)\n"
     ]
    }
   ],
   "source": [
    "print(inData_train.shape)\n",
    "print(outData_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        in_shape = (batch_size, sequence_length, num_inData_signals)\n",
    "        in_batch = np.zeros(shape=in_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        out_shape = (batch_size, sequence_length, num_outData_signals)\n",
    "        out_batch = np.zeros(shape=out_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            # This points somewhere into the augmented series range.\n",
    "            idaugmnt = np.random.randint(agmntCount)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            in_batch[i] = inData_train[idaugmnt, idx:idx+sequence_length,:]\n",
    "            out_batch[i] = outData_train[idaugmnt, idx:idx+sequence_length,:]\n",
    "        \n",
    "        yield (in_batch, out_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length=200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=batch_size,\n",
    "                            sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_batch, out_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(400, 200, 11)\n",
      "(400, 200, 1)\n"
     ]
    }
   ],
   "source": [
    "print(in_batch.shape)\n",
    "print(out_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbefbe38bd0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 0   # First sequence in the batch.\n",
    "signal = 1  # First signal from the 21 input-signals.\n",
    "seq = in_batch[batch,predictSteps:predictSteps+50, signal]\n",
    "plt.scatter(np.arange(0, len(seq)), seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fbefbec4350>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = out_batch[batch, 0:50, 0]\n",
    "plt.scatter(np.arange(0, len(seq)),seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(inData_test[0,:,:], axis=0),\n",
    "                   np.expand_dims(outData_test[0,:,:], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(GRU(units=512,\n",
    "              return_sequences=True,\n",
    "              input_shape=(None, num_inData_signals,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Dense(num_outData_signals, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loss_mse_warmup(y_true, y_pred):\n",
    "#    \"\"\"\n",
    "#    Calculate the Mean Squared Error between y_true and y_pred,\n",
    "#    but ignore the beginning \"warmup\" part of the sequences.\n",
    "#    \n",
    "#    y_true is the desired output.\n",
    "#    y_pred is the model's output.\n",
    "#    \"\"\"\n",
    "\n",
    "    # The shape of both input tensors are:\n",
    "    # [batch_size, sequence_length, num_y_signals].\n",
    "\n",
    "    # Ignore the \"warmup\" parts of the sequences\n",
    "    # by taking slices of the tensors.\n",
    "#    y_true_slice = y_true[:, warmup_steps:, :]\n",
    "#    y_pred_slice = y_pred[:, warmup_steps:, :]\n",
    "\n",
    "    # These sliced tensors both have this shape:\n",
    "    # [batch_size, sequence_length - warmup_steps, num_y_signals]\n",
    "\n",
    "    # Calculate the MSE loss for each value in these tensors.\n",
    "    # This outputs a 3-rank tensor of the same shape.\n",
    "#    loss = tf.losses.mean_squared_error(labels=y_true_slice,\n",
    "#                                        predictions=y_pred_slice)\n",
    "\n",
    "    # Keras may reduce this across the first axis (the batch)\n",
    "    # but the semantics are unclear, so to be sure we use\n",
    "    # the loss across the entire tensor, we reduce it to a\n",
    "    # single scalar with the mean function.\n",
    "#    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "#    return loss_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer = RMSprop(lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(Adam(), loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11253776207977105698\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3574530048\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3951582542222154703\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 770, pci bus id: 0000:01:00.0, compute capability: 3.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_1 (GRU)                  (None, None, 512)         804864    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           513       \n",
      "=================================================================\n",
      "Total params: 805,377\n",
      "Trainable params: 805,377\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = str(outputBlockId)+'_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=6, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback_tensorboard = keras.callbacks.TensorBoard(log_dir=\"logdir/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-5,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "            callback_checkpoint,\n",
    "            callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gru_1/while/body/_1/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_1664]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1730\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1731\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    218\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                                             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                                             reset_metrics=False)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3727\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3729\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \"\"\"\n\u001b[0;32m-> 1551\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1591\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1592\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1593\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[400,512] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gru_1/while/body/_1/mul}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_1664]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(generator=generator,\n",
    "                    epochs=1000,\n",
    "                    steps_per_epoch=15,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
