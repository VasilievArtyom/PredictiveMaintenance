{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import signal\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense, GRU, Embedding, Dense, Activation, Dropout, LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "\n",
    "outpath = \"../../../plots/temperatures\"\n",
    "inpath = \"../../../\"\n",
    "\n",
    "currentfile = \"Imitator_2_2400.csv\"\n",
    "\n",
    "# Read from file\n",
    "strdatatype = np.dtype([('N', np.int_, (2,)), ('Time_Count', np.int_ ), ('Mode', np.int_ ),\n",
    "                        ('T', np.float_, (10,)), ('S', np.bool_, (10,)), ('System_State', np.bool_ )])\n",
    "N, Time_Count, Mode, T, S, System_State = np.loadtxt(path.join(inpath, currentfile), \n",
    "                                                     unpack=True, delimiter=';', skiprows=1, dtype=strdatatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_possible_model_temperature = 18\n",
    "min_possible_model_temperature = 66\n",
    "def scale_T(_T):\n",
    "    return ((_T - min_possible_model_temperature) / (max_possible_model_temperature - min_possible_model_temperature)) * 2.0 - 1.0\n",
    "\n",
    "def unscale_T(_T):\n",
    "    return ((_T + 1.0) / 2.0) * (max_possible_model_temperature - min_possible_model_temperature) + min_possible_model_temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputBlockId=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "sT = scale_T(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.14203288058243 18.40911018644466\n",
      "0.9829537422314722 -0.9642513700242681\n"
     ]
    }
   ],
   "source": [
    "print(np.amax(T), np.amin(T))\n",
    "print(np.amax(sT), np.amin(sT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = np.amin(np.abs(sT[:-2, :] - sT[1:-1, :])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.885262602116747e-06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data augmintation -- 50000 slightly tuned copies of T\n",
    "agmntCount=5000\n",
    "agmntdT=np.zeros((agmntCount, np.size(sT[:,0]), np.size(sT[0,:])))\n",
    "agmntdT[0,:,:] = sT\n",
    "np.random.seed(0)\n",
    "mu, sigma = 0, delta*1000\n",
    "for i in range(1, agmntCount):\n",
    "    agmntdT[i] = agmntdT[0] + np.random.normal(mu, sigma, (np.size(sT[:,0]), np.size(sT[0,:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2401, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agmntdT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictSteps = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep dataset tail for validate prediction quality\n",
    "cutFromTail = 150\n",
    "#In order to have shifted and unshifted series with same shape\n",
    "t = cutFromTail + predictSteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inData = np.zeros((agmntCount, np.size(sT[:-t,0]), np.size(sT[0,:]) + 1))\n",
    "#for i in range(0, agmntCount):\n",
    "#    inData[i,:,0] = Mode[:-t] / np.amax(Mode[:-t])\n",
    "#    inData[i,:,1:]= agmntdT[i,:-t,:]\n",
    "\n",
    "inData = np.zeros((agmntCount, np.size(sT[:-t,0]), np.size(sT[0,:])))\n",
    "for i in range(0, agmntCount):\n",
    "    inData[i,:,:]= agmntdT[i,:-t,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2250, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "outData = np.expand_dims(agmntdT[:,predictSteps:-cutFromTail,outputBlockId], axis=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2250, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data = len(inData[0,:,0])\n",
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1867"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_train = int(train_split * num_data)\n",
    "num_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "383"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_test = num_data - num_train\n",
    "num_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inData_train = inData[:, 0:num_train, :]\n",
    "inData_test = inData[:, num_train:, :]\n",
    "len(inData_train[0,:,0]) + len(inData_test[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2250"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outData_train = outData[:, 0:num_train, :]\n",
    "outData_test = outData[:, num_train:, :]\n",
    "len(outData_train[0,:,0]) + len(outData_test[0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_inData_signals = inData.shape[2]\n",
    "num_inData_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_outData_signals = outData.shape[2]\n",
    "num_outData_signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 3072164182496763927\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3522887680\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3139609261579845002\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 770, pci bus id: 0000:01:00.0, compute capability: 3.0\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_generator(batch_size, sequence_length):\n",
    "    \"\"\"\n",
    "    Generator function for creating random batches of training-data.\n",
    "    \"\"\"\n",
    "    # Infinite loop.\n",
    "    while True:\n",
    "        # Allocate a new array for the batch of input-signals.\n",
    "        in_shape = (batch_size, sequence_length, num_inData_signals)\n",
    "        in_batch = np.zeros(shape=in_shape, dtype=np.float16)\n",
    "\n",
    "        # Allocate a new array for the batch of output-signals.\n",
    "        out_shape = (batch_size, sequence_length, num_outData_signals)\n",
    "        out_batch = np.zeros(shape=out_shape, dtype=np.float16)\n",
    "\n",
    "        # Fill the batch with random sequences of data.\n",
    "        for i in range(batch_size):\n",
    "            # Get a random start-index.\n",
    "            # This points somewhere into the training-data.\n",
    "            idx = np.random.randint(num_train - sequence_length)\n",
    "            # This points somewhere into the augmented series range.\n",
    "            idaugmnt = np.random.randint(agmntCount)\n",
    "            \n",
    "            # Copy the sequences of data starting at this index.\n",
    "            in_batch[i] = inData_train[idaugmnt, idx:idx+sequence_length,:]\n",
    "            out_batch[i] = outData_train[idaugmnt, idx:idx+sequence_length,:]\n",
    "        \n",
    "        yield (in_batch, out_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sequence_length=576\n",
    "sequence_length=120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = batch_generator(batch_size=batch_size,\n",
    "                            sequence_length=sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_batch, out_batch = next(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 120, 10)\n",
      "(500, 120, 1)\n"
     ]
    }
   ],
   "source": [
    "print(in_batch.shape)\n",
    "print(out_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb07b496f90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "batch = 0   # First sequence in the batch.\n",
    "seq = in_batch[batch,predictSteps:predictSteps+50, outputBlockId]\n",
    "plt.scatter(np.arange(0, len(seq)), seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fb07b402150>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq = out_batch[batch, 0:50, 0]\n",
    "plt.scatter(np.arange(0, len(seq)),seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_data = (np.expand_dims(inData_test[0,:,:], axis=0),\n",
    "                   np.expand_dims(outData_test[0,:,:], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(LSTM(512, return_sequences=True, input_shape=(None, num_inData_signals,)))\n",
    "model.add(LSTM(5, return_sequences=True))\n",
    "model.add(Dense(1, activation = \"linear\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "warmup_steps = 10\n",
    "import keras.backend as K\n",
    "def loss_mse_warmup(y_true, y_pred): \n",
    "    return K.mean(K.square(y_pred[:, warmup_steps:, :]-y_true[:, warmup_steps:, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.compile(Adam(learning_rate=1e-4), loss='mean_absolute_error')\n",
    "model.compile(Adam(learning_rate=5e-5), loss=loss_mse_warmup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, None, 512)         1071104   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, None, 5)           10360     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 1)           6         \n",
      "=================================================================\n",
      "Total params: 1,081,470\n",
      "Trainable params: 1,081,470\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = str(outputBlockId)+'_multistep_test.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=5, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                                       factor=0.1,\n",
    "                                       min_lr=1e-9,\n",
    "                                       patience=0,\n",
    "                                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "            callback_checkpoint,\n",
    "            callback_reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try:\n",
    "#    model.load_weights(\"0_multistep_test.keras\")\n",
    "#except Exception as error:\n",
    "#    print(\"Error trying to load checkpoint.\")\n",
    "#    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100000\n",
      "10/10 [==============================] - 6s 588ms/step - loss: 0.1140 - val_loss: 0.1043\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.10426, saving model to 2_multistep_test.keras\n",
      "Epoch 2/100000\n",
      "10/10 [==============================] - 5s 530ms/step - loss: 0.0932 - val_loss: 0.0928\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.10426 to 0.09275, saving model to 2_multistep_test.keras\n",
      "Epoch 3/100000\n",
      "10/10 [==============================] - 5s 533ms/step - loss: 0.0825 - val_loss: 0.0725\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09275 to 0.07249, saving model to 2_multistep_test.keras\n",
      "Epoch 4/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0744 - val_loss: 0.0621\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.07249 to 0.06212, saving model to 2_multistep_test.keras\n",
      "Epoch 5/100000\n",
      "10/10 [==============================] - 5s 536ms/step - loss: 0.0665 - val_loss: 0.0561\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.06212 to 0.05607, saving model to 2_multistep_test.keras\n",
      "Epoch 6/100000\n",
      "10/10 [==============================] - 5s 544ms/step - loss: 0.0610 - val_loss: 0.0492\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.05607 to 0.04925, saving model to 2_multistep_test.keras\n",
      "Epoch 7/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0555 - val_loss: 0.0475\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.04925 to 0.04755, saving model to 2_multistep_test.keras\n",
      "Epoch 8/100000\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.0508 - val_loss: 0.0464\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.04755 to 0.04642, saving model to 2_multistep_test.keras\n",
      "Epoch 9/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0477 - val_loss: 0.0449\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.04642 to 0.04490, saving model to 2_multistep_test.keras\n",
      "Epoch 10/100000\n",
      "10/10 [==============================] - 5s 526ms/step - loss: 0.0445 - val_loss: 0.0426\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.04490 to 0.04258, saving model to 2_multistep_test.keras\n",
      "Epoch 11/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0418 - val_loss: 0.0407\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.04258 to 0.04065, saving model to 2_multistep_test.keras\n",
      "Epoch 12/100000\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.0393 - val_loss: 0.0389\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.04065 to 0.03892, saving model to 2_multistep_test.keras\n",
      "Epoch 13/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0365 - val_loss: 0.0373\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.03892 to 0.03733, saving model to 2_multistep_test.keras\n",
      "Epoch 14/100000\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.0339 - val_loss: 0.0354\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.03733 to 0.03537, saving model to 2_multistep_test.keras\n",
      "Epoch 15/100000\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0316 - val_loss: 0.0332\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.03537 to 0.03321, saving model to 2_multistep_test.keras\n",
      "Epoch 16/100000\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 0.0292 - val_loss: 0.0326\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.03321 to 0.03259, saving model to 2_multistep_test.keras\n",
      "Epoch 17/100000\n",
      "10/10 [==============================] - 5s 523ms/step - loss: 0.0274 - val_loss: 0.0302\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.03259 to 0.03017, saving model to 2_multistep_test.keras\n",
      "Epoch 18/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0257 - val_loss: 0.0287\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.03017 to 0.02873, saving model to 2_multistep_test.keras\n",
      "Epoch 19/100000\n",
      "10/10 [==============================] - 5s 528ms/step - loss: 0.0241 - val_loss: 0.0277\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.02873 to 0.02774, saving model to 2_multistep_test.keras\n",
      "Epoch 20/100000\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.0225 - val_loss: 0.0247\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.02774 to 0.02468, saving model to 2_multistep_test.keras\n",
      "Epoch 21/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0226 - val_loss: 0.0235\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.02468 to 0.02351, saving model to 2_multistep_test.keras\n",
      "Epoch 22/100000\n",
      "10/10 [==============================] - 5s 525ms/step - loss: 0.0207 - val_loss: 0.0225\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.02351 to 0.02250, saving model to 2_multistep_test.keras\n",
      "Epoch 23/100000\n",
      "10/10 [==============================] - 5s 528ms/step - loss: 0.0196 - val_loss: 0.0214\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.02250 to 0.02145, saving model to 2_multistep_test.keras\n",
      "Epoch 24/100000\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0189 - val_loss: 0.0198\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.02145 to 0.01978, saving model to 2_multistep_test.keras\n",
      "Epoch 25/100000\n",
      "10/10 [==============================] - 5s 535ms/step - loss: 0.0180 - val_loss: 0.0189\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01978 to 0.01894, saving model to 2_multistep_test.keras\n",
      "Epoch 26/100000\n",
      "10/10 [==============================] - 5s 524ms/step - loss: 0.0180 - val_loss: 0.0206\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.01894\n",
      "\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-06.\n",
      "Epoch 27/100000\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0175 - val_loss: 0.0187\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01894 to 0.01869, saving model to 2_multistep_test.keras\n",
      "Epoch 28/100000\n",
      "10/10 [==============================] - 5s 531ms/step - loss: 0.0170 - val_loss: 0.0182\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.01869 to 0.01820, saving model to 2_multistep_test.keras\n",
      "Epoch 29/100000\n",
      " 4/10 [===========>..................] - ETA: 3s - loss: 0.0168"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(generator=generator,\n",
    "                    epochs=100000,\n",
    "                    steps_per_epoch=10,\n",
    "                    validation_data=validation_data,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.evaluate(x=np.expand_dims(inData_test[0], axis=0),\n",
    "                        y=np.expand_dims(outData_test[0], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loss (test-set):\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(start_idx, length=100, train=True):\n",
    "    \"\"\"\n",
    "    Plot the predicted and true output-signals.\n",
    "    \n",
    "    :param start_idx: Start-index for the time-series.\n",
    "    :param length: Sequence-length to process and plot.\n",
    "    :param train: Boolean whether to use training- or test-set.\n",
    "    \"\"\"\n",
    "    \n",
    "    if train:\n",
    "        # Use training-data.\n",
    "        x = inData_train[0]\n",
    "        y_true = outData_train[0]\n",
    "    else:\n",
    "        # Use test-data.\n",
    "        x = inData_test[0]\n",
    "        y_true = outData_test[0]\n",
    "    \n",
    "    # End-index for the sequences.\n",
    "    end_idx = start_idx + length\n",
    "    \n",
    "    # Select the sequences from the given start-index and\n",
    "    # of the given length.\n",
    "    x = x[start_idx:end_idx]\n",
    "    y_true = y_true[start_idx:end_idx]\n",
    "    \n",
    "    # Input-signals for the model.\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "\n",
    "    # Use the model to predict the output-signals.\n",
    "    y_pred = model.predict(x)\n",
    "    print(shape(x))\n",
    "    print(shape(y_pred))\n",
    "        \n",
    "    # Get the output-signal predicted by the model.\n",
    "    signal_pred = y_pred\n",
    "        \n",
    "    # Get the true output-signal from the data-set.\n",
    "    signal_true = y_true\n",
    "    \n",
    "    # Make the plotting-canvas bigger.\n",
    "    plt.figure(figsize=(15,5))\n",
    "        \n",
    "    # Plot and compare the two signals.\n",
    "    plt.plot(signal_true, label='true')\n",
    "    plt.scatter(np.arange(0, len(signal_pred[0])), signal_pred[0,:,:], label='pred', color='r')\n",
    "\n",
    "        \n",
    "    # Plot labels etc.\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(start_idx=0, length=400, train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length_for_predict = sequence_length\n",
    "\n",
    "def predStepForAllBlc(_in):\n",
    "    _out = np.zeros((1, sequence_length_for_predict, 10))\n",
    "    for blk_id in range(0, 10):\n",
    "            path_to_current_model = str(blk_id)+'_multistep_test.keras'\n",
    "            try:\n",
    "                model.load_weights(path_to_current_model)\n",
    "            except Exception as error:\n",
    "                print(\"Error trying to load model for block \"+str(blk_id+1))\n",
    "                print(error)\n",
    "            _out[0, :, blk_id] = model.predict(_in)[0,:,0]\n",
    "    return _out[0, -predictSteps:, :]\n",
    "            \n",
    "def performOfSamplePrediction(outOfSampleCount):    \n",
    "    prediction = np.zeros(((outOfSampleCount // predictSteps) * (predictSteps + 1), 10))\n",
    "    \n",
    "    predictBase = np.zeros((1, sequence_length_for_predict, num_inData_signals))\n",
    "    onStepPredict = np.zeros((1, sequence_length_for_predict, 10))\n",
    "   \n",
    "    predictBase[0,:,:] = sT[-(sequence_length_for_predict + cutFromTail): -cutFromTail,:]\n",
    "    \n",
    "    prediction[0:predictSteps,:] = predStepForAllBlc(predictBase)\n",
    "    for step in range(predictSteps,outOfSampleCount,predictSteps):\n",
    "            predictBase[0,:-predictSteps,:] = predictBase[0,predictSteps:,:]\n",
    "            predictBase[0,-predictSteps:,:] = prediction[(step - predictSteps):step,:]\n",
    "            prediction[step:step+predictSteps,:] = predStepForAllBlc(predictBase)\n",
    "    return prediction\n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = performOfSamplePrediction(predictSteps + cutFromTail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for _id in range (0, 10):\n",
    "    plt.figure(figsize=(15,2))\n",
    "    plt.plot(pred[:,_id])\n",
    "    plt.plot(sT[-(predictSteps + cutFromTail):, _id], color='gray')\n",
    "    plt.ylabel(\"Block\"+str(_id+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
