{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d43cbfe77ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rc('text', usetex=True)\n",
    "\n",
    "inpath = \"../../\"\n",
    "\n",
    "currentfile = \"Imitator_2_2400.csv\"\n",
    "\n",
    "# Read from file\n",
    "strdatatype = np.dtype([('N', np.int_, (2,)), ('Time_Count', np.int_ ), ('Mode', np.int_ ),\n",
    "                            ('T', np.float_, (10,)), ('S', np.bool_, (10,)), ('System_State', np.bool_ )])\n",
    "N, Time_Count, Mode, T, S, System_State = np.loadtxt(path.join(inpath, currentfile),\n",
    "        unpack=True, delimiter=';', skiprows=1, dtype=strdatatype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_enc(_data_full, _now, _depth):\n",
    "    '''\n",
    "    returns slice of inintial array to pass it to LSTM input on one given timestamp\n",
    "    '''\n",
    "    data_slice = _data_full[_now - _depth: _now,:]\n",
    "    return data_slice\n",
    "\n",
    "def slice_pred(_data_full, _now, _depth):\n",
    "    '''\n",
    "    returns slice of inintial array to pass it to LSTM input on one given timestamp\n",
    "    '''\n",
    "    data_slice = _data_full[_now: _now + _depth]\n",
    "    return data_slice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_steps = 20\n",
    "\n",
    "first_n = N[0,0] \n",
    "last_n = N[-1,-1]\n",
    "\n",
    "val_pred_start = last_n - pred_steps + 1\n",
    "val_pred_end = last_n\n",
    "val_enc_start = first_n + pred_steps +1\n",
    "val_enc_end = last_n - pred_steps\n",
    "\n",
    "train_enc_start = first_n\n",
    "train_enc_end = last_n - 2 * pred_steps\n",
    "train_pred_start = last_n - 2 * pred_steps + 1\n",
    "train_pred_end = last_n - pred_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 50 # LSTM hidden units\n",
    "dropout = .20 \n",
    "\n",
    "# Define an input series and encode it with an LSTM. \n",
    "encoder_inputs = Input(shape=(None, 1)) \n",
    "encoder = LSTM(latent_dim, dropout=dropout, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "\n",
    "# We discard `encoder_outputs` and only keep the final states. These represent the \"context\"\n",
    "# vector that we use as the basis for decoding.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "# This is where teacher forcing inputs are fed in.\n",
    "decoder_inputs = Input(shape=(None, 1)) \n",
    "\n",
    "# We set up our decoder using `encoder_states` as initial state.  \n",
    "# We return full output sequences and return internal states as well. \n",
    "# We don't use the return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, dropout=dropout, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "\n",
    "decoder_dense = Dense(1) # 1 continuous output at each timestep\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 1)      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 50), (None,  10400       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 50), ( 10400       input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 1)      51          lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 20,851\n",
      "Trainable params: 20,851\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8 samples, validate on 2 samples\n",
      "Epoch 1/300\n",
      "8/8 [==============================] - 6s 764ms/step - loss: 37.0907 - val_loss: 29.7586\n",
      "Epoch 2/300\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 37.0219 - val_loss: 29.6828\n",
      "Epoch 3/300\n",
      "8/8 [==============================] - 4s 545ms/step - loss: 36.7903 - val_loss: 29.6080\n",
      "Epoch 4/300\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 36.8183 - val_loss: 29.5337\n",
      "Epoch 5/300\n",
      "8/8 [==============================] - 5s 580ms/step - loss: 36.8286 - val_loss: 29.4598\n",
      "Epoch 6/300\n",
      "8/8 [==============================] - 5s 582ms/step - loss: 36.5839 - val_loss: 29.3861\n",
      "Epoch 7/300\n",
      "8/8 [==============================] - 5s 577ms/step - loss: 36.6250 - val_loss: 29.3124\n",
      "Epoch 8/300\n",
      "8/8 [==============================] - 4s 561ms/step - loss: 36.4913 - val_loss: 29.2387\n",
      "Epoch 9/300\n",
      "8/8 [==============================] - 4s 551ms/step - loss: 36.4721 - val_loss: 29.1644\n",
      "Epoch 10/300\n",
      "8/8 [==============================] - 4s 552ms/step - loss: 36.4591 - val_loss: 29.0897\n",
      "Epoch 11/300\n",
      "8/8 [==============================] - 5s 566ms/step - loss: 36.3952 - val_loss: 29.0142\n",
      "Epoch 12/300\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 36.2388 - val_loss: 28.9381\n",
      "Epoch 13/300\n",
      "8/8 [==============================] - 5s 639ms/step - loss: 36.2828 - val_loss: 28.8620\n",
      "Epoch 14/300\n",
      "8/8 [==============================] - 4s 553ms/step - loss: 36.2834 - val_loss: 28.7863\n",
      "Epoch 15/300\n",
      "8/8 [==============================] - 5s 623ms/step - loss: 36.1349 - val_loss: 28.7109\n",
      "Epoch 16/300\n",
      "8/8 [==============================] - 5s 572ms/step - loss: 35.9503 - val_loss: 28.6356\n",
      "Epoch 17/300\n",
      "8/8 [==============================] - 4s 537ms/step - loss: 35.7208 - val_loss: 28.5610\n",
      "Epoch 18/300\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 35.7126 - val_loss: 28.4886\n",
      "Epoch 19/300\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 35.8232 - val_loss: 28.4199\n",
      "Epoch 20/300\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 35.8405 - val_loss: 28.3550\n",
      "Epoch 21/300\n",
      "8/8 [==============================] - 5s 616ms/step - loss: 35.7124 - val_loss: 28.2922\n",
      "Epoch 22/300\n",
      "8/8 [==============================] - 5s 576ms/step - loss: 35.5113 - val_loss: 28.2297\n",
      "Epoch 23/300\n",
      "8/8 [==============================] - 4s 553ms/step - loss: 35.4098 - val_loss: 28.1673\n",
      "Epoch 24/300\n",
      "8/8 [==============================] - 4s 552ms/step - loss: 35.4893 - val_loss: 28.1045\n",
      "Epoch 25/300\n",
      "8/8 [==============================] - 5s 568ms/step - loss: 35.3200 - val_loss: 28.0416\n",
      "Epoch 26/300\n",
      "8/8 [==============================] - 4s 542ms/step - loss: 35.3025 - val_loss: 27.9784\n",
      "Epoch 27/300\n",
      "8/8 [==============================] - 5s 565ms/step - loss: 35.1685 - val_loss: 27.9150\n",
      "Epoch 28/300\n",
      "8/8 [==============================] - 5s 573ms/step - loss: 35.1137 - val_loss: 27.8515\n",
      "Epoch 29/300\n",
      "8/8 [==============================] - 5s 567ms/step - loss: 34.9438 - val_loss: 27.7878\n",
      "Epoch 30/300\n",
      "8/8 [==============================] - 5s 652ms/step - loss: 34.9438 - val_loss: 27.7239\n",
      "Epoch 31/300\n",
      "8/8 [==============================] - 4s 545ms/step - loss: 34.8139 - val_loss: 27.6600\n",
      "Epoch 32/300\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 34.9341 - val_loss: 27.5961\n",
      "Epoch 33/300\n",
      "8/8 [==============================] - 5s 581ms/step - loss: 34.7255 - val_loss: 27.5324\n",
      "Epoch 34/300\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 34.7628 - val_loss: 27.4689\n",
      "Epoch 35/300\n",
      "8/8 [==============================] - 4s 549ms/step - loss: 34.6068 - val_loss: 27.4058\n",
      "Epoch 36/300\n",
      "8/8 [==============================] - 4s 489ms/step - loss: 34.6012 - val_loss: 27.3432\n",
      "Epoch 37/300\n",
      "8/8 [==============================] - 5s 584ms/step - loss: 34.4617 - val_loss: 27.2814\n",
      "Epoch 38/300\n",
      "8/8 [==============================] - 4s 535ms/step - loss: 34.5225 - val_loss: 27.2203\n",
      "Epoch 39/300\n",
      "8/8 [==============================] - 4s 505ms/step - loss: 34.4473 - val_loss: 27.1601\n",
      "Epoch 40/300\n",
      "8/8 [==============================] - 4s 525ms/step - loss: 34.2447 - val_loss: 27.1008\n",
      "Epoch 41/300\n",
      "8/8 [==============================] - 5s 575ms/step - loss: 34.2282 - val_loss: 27.0421\n",
      "Epoch 42/300\n",
      "8/8 [==============================] - 5s 613ms/step - loss: 34.2484 - val_loss: 26.9838\n",
      "Epoch 43/300\n",
      "8/8 [==============================] - 5s 599ms/step - loss: 34.1819 - val_loss: 26.9255\n",
      "Epoch 44/300\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 34.0100 - val_loss: 26.8671\n",
      "Epoch 45/300\n",
      "8/8 [==============================] - 5s 612ms/step - loss: 34.0489 - val_loss: 26.8084\n",
      "Epoch 46/300\n",
      "8/8 [==============================] - 5s 572ms/step - loss: 33.9050 - val_loss: 26.7493\n",
      "Epoch 47/300\n",
      "8/8 [==============================] - 4s 556ms/step - loss: 33.7934 - val_loss: 26.6900\n",
      "Epoch 48/300\n",
      "8/8 [==============================] - 4s 541ms/step - loss: 33.8002 - val_loss: 26.6303\n",
      "Epoch 49/300\n",
      "8/8 [==============================] - 5s 587ms/step - loss: 33.7183 - val_loss: 26.5702\n",
      "Epoch 50/300\n",
      "8/8 [==============================] - 4s 488ms/step - loss: 33.7194 - val_loss: 26.5098\n",
      "Epoch 51/300\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 33.6238 - val_loss: 26.4490\n",
      "Epoch 52/300\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 33.5769 - val_loss: 26.3880\n",
      "Epoch 53/300\n",
      "8/8 [==============================] - 5s 589ms/step - loss: 33.5510 - val_loss: 26.3268\n",
      "Epoch 54/300\n",
      "8/8 [==============================] - 5s 585ms/step - loss: 33.5238 - val_loss: 26.2656\n",
      "Epoch 55/300\n",
      "8/8 [==============================] - 5s 572ms/step - loss: 33.3790 - val_loss: 26.2048\n",
      "Epoch 56/300\n",
      "8/8 [==============================] - 4s 538ms/step - loss: 33.3572 - val_loss: 26.1441\n",
      "Epoch 57/300\n",
      "8/8 [==============================] - 4s 535ms/step - loss: 33.2516 - val_loss: 26.0835\n",
      "Epoch 58/300\n",
      "8/8 [==============================] - 5s 563ms/step - loss: 33.2227 - val_loss: 26.0231\n",
      "Epoch 59/300\n",
      "8/8 [==============================] - 4s 545ms/step - loss: 33.1851 - val_loss: 25.9629\n",
      "Epoch 60/300\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 33.1335 - val_loss: 25.9031\n",
      "Epoch 61/300\n",
      "8/8 [==============================] - 4s 557ms/step - loss: 33.0526 - val_loss: 25.8438\n",
      "Epoch 62/300\n",
      "8/8 [==============================] - 5s 581ms/step - loss: 33.0177 - val_loss: 25.7851\n",
      "Epoch 63/300\n",
      "8/8 [==============================] - 5s 593ms/step - loss: 32.8972 - val_loss: 25.7272\n",
      "Epoch 64/300\n",
      "8/8 [==============================] - 5s 613ms/step - loss: 32.8539 - val_loss: 25.6699\n",
      "Epoch 65/300\n",
      "8/8 [==============================] - 5s 572ms/step - loss: 32.8208 - val_loss: 25.6131\n",
      "Epoch 66/300\n",
      "8/8 [==============================] - 4s 562ms/step - loss: 32.7943 - val_loss: 25.5569\n",
      "Epoch 67/300\n",
      "8/8 [==============================] - 4s 528ms/step - loss: 32.7467 - val_loss: 25.5013\n",
      "Epoch 68/300\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 32.6887 - val_loss: 25.4461\n",
      "Epoch 69/300\n",
      "8/8 [==============================] - 5s 611ms/step - loss: 32.5835 - val_loss: 25.3910\n",
      "Epoch 70/300\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 32.5493 - val_loss: 25.3361\n",
      "Epoch 71/300\n",
      "8/8 [==============================] - 5s 582ms/step - loss: 32.4269 - val_loss: 25.2814\n",
      "Epoch 72/300\n",
      "8/8 [==============================] - 5s 568ms/step - loss: 32.3527 - val_loss: 25.2267\n",
      "Epoch 73/300\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 32.3302 - val_loss: 25.1720\n",
      "Epoch 74/300\n",
      "8/8 [==============================] - 5s 585ms/step - loss: 32.2664 - val_loss: 25.1173\n",
      "Epoch 75/300\n",
      "8/8 [==============================] - 5s 578ms/step - loss: 32.2249 - val_loss: 25.0625\n",
      "Epoch 76/300\n",
      "8/8 [==============================] - 5s 565ms/step - loss: 32.1167 - val_loss: 25.0074\n",
      "Epoch 77/300\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 32.0809 - val_loss: 24.9520\n",
      "Epoch 78/300\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 32.0400 - val_loss: 24.8963\n",
      "Epoch 79/300\n",
      "8/8 [==============================] - 5s 610ms/step - loss: 31.9641 - val_loss: 24.8400\n",
      "Epoch 80/300\n",
      "8/8 [==============================] - 5s 580ms/step - loss: 31.9252 - val_loss: 24.7833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 81/300\n",
      "8/8 [==============================] - 4s 539ms/step - loss: 31.8695 - val_loss: 24.7258\n",
      "Epoch 82/300\n",
      "8/8 [==============================] - 4s 511ms/step - loss: 31.8057 - val_loss: 24.6675\n",
      "Epoch 83/300\n",
      "8/8 [==============================] - 5s 570ms/step - loss: 31.7490 - val_loss: 24.6083\n",
      "Epoch 84/300\n",
      "8/8 [==============================] - 5s 594ms/step - loss: 31.7127 - val_loss: 24.5482\n",
      "Epoch 85/300\n",
      "8/8 [==============================] - 5s 650ms/step - loss: 31.6380 - val_loss: 24.4870\n",
      "Epoch 86/300\n",
      "8/8 [==============================] - 5s 610ms/step - loss: 31.5885 - val_loss: 24.4249\n",
      "Epoch 87/300\n",
      "8/8 [==============================] - 5s 585ms/step - loss: 31.5200 - val_loss: 24.3619\n",
      "Epoch 88/300\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 31.4536 - val_loss: 24.2981\n",
      "Epoch 89/300\n",
      "8/8 [==============================] - 4s 502ms/step - loss: 31.4141 - val_loss: 24.2341\n",
      "Epoch 90/300\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 31.3574 - val_loss: 24.1702\n",
      "Epoch 91/300\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 31.3294 - val_loss: 24.1063\n",
      "Epoch 92/300\n",
      "8/8 [==============================] - 5s 599ms/step - loss: 31.2327 - val_loss: 24.0424\n",
      "Epoch 93/300\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 31.2205 - val_loss: 23.9789\n",
      "Epoch 94/300\n",
      "8/8 [==============================] - 4s 554ms/step - loss: 31.1482 - val_loss: 23.9159\n",
      "Epoch 95/300\n",
      "8/8 [==============================] - 4s 445ms/step - loss: 31.0359 - val_loss: 23.8532\n",
      "Epoch 96/300\n",
      "8/8 [==============================] - 4s 551ms/step - loss: 31.0124 - val_loss: 23.7911\n",
      "Epoch 97/300\n",
      "8/8 [==============================] - 5s 599ms/step - loss: 30.9745 - val_loss: 23.7297\n",
      "Epoch 98/300\n",
      "8/8 [==============================] - 5s 581ms/step - loss: 30.8501 - val_loss: 23.6690\n",
      "Epoch 99/300\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 30.8204 - val_loss: 23.6091\n",
      "Epoch 100/300\n",
      "8/8 [==============================] - 5s 613ms/step - loss: 30.7534 - val_loss: 23.5498\n",
      "Epoch 101/300\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 30.6759 - val_loss: 23.4911\n",
      "Epoch 102/300\n",
      "8/8 [==============================] - 4s 549ms/step - loss: 30.5987 - val_loss: 23.4328\n",
      "Epoch 103/300\n",
      "8/8 [==============================] - 5s 567ms/step - loss: 30.5456 - val_loss: 23.3752\n",
      "Epoch 104/300\n",
      "8/8 [==============================] - 5s 567ms/step - loss: 30.4730 - val_loss: 23.3182\n",
      "Epoch 105/300\n",
      "8/8 [==============================] - 5s 585ms/step - loss: 30.4155 - val_loss: 23.2615\n",
      "Epoch 106/300\n",
      "8/8 [==============================] - 5s 589ms/step - loss: 30.3558 - val_loss: 23.2052\n",
      "Epoch 107/300\n",
      "8/8 [==============================] - 5s 565ms/step - loss: 30.3063 - val_loss: 23.1492\n",
      "Epoch 108/300\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 30.2350 - val_loss: 23.0935\n",
      "Epoch 109/300\n",
      "8/8 [==============================] - 5s 617ms/step - loss: 30.1900 - val_loss: 23.0380\n",
      "Epoch 110/300\n",
      "8/8 [==============================] - 5s 578ms/step - loss: 30.1309 - val_loss: 22.9826\n",
      "Epoch 111/300\n",
      "8/8 [==============================] - 5s 624ms/step - loss: 30.0748 - val_loss: 22.9274\n",
      "Epoch 112/300\n",
      "8/8 [==============================] - 5s 573ms/step - loss: 30.0171 - val_loss: 22.8723\n",
      "Epoch 113/300\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 29.9449 - val_loss: 22.8173\n",
      "Epoch 114/300\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 29.8936 - val_loss: 22.7624\n",
      "Epoch 115/300\n",
      "8/8 [==============================] - 5s 584ms/step - loss: 29.8237 - val_loss: 22.7076\n",
      "Epoch 116/300\n",
      "8/8 [==============================] - 5s 577ms/step - loss: 29.7931 - val_loss: 22.6528\n",
      "Epoch 117/300\n",
      "8/8 [==============================] - 5s 579ms/step - loss: 29.7379 - val_loss: 22.5979\n",
      "Epoch 118/300\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 29.6872 - val_loss: 22.5431\n",
      "Epoch 119/300\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 29.6230 - val_loss: 22.4882\n",
      "Epoch 120/300\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 29.5873 - val_loss: 22.4332\n",
      "Epoch 121/300\n",
      "8/8 [==============================] - 5s 571ms/step - loss: 29.5126 - val_loss: 22.3780\n",
      "Epoch 122/300\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 29.4737 - val_loss: 22.3226\n",
      "Epoch 123/300\n",
      "8/8 [==============================] - 5s 563ms/step - loss: 29.4135 - val_loss: 22.2668\n",
      "Epoch 124/300\n",
      "8/8 [==============================] - 6s 748ms/step - loss: 29.3569 - val_loss: 22.2109\n",
      "Epoch 125/300\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 29.2926 - val_loss: 22.1550\n",
      "Epoch 126/300\n",
      "8/8 [==============================] - 5s 679ms/step - loss: 29.2379 - val_loss: 22.0993\n",
      "Epoch 127/300\n",
      "8/8 [==============================] - 4s 539ms/step - loss: 29.1915 - val_loss: 22.0440\n",
      "Epoch 128/300\n",
      "8/8 [==============================] - 5s 577ms/step - loss: 29.1096 - val_loss: 21.9890\n",
      "Epoch 129/300\n",
      "8/8 [==============================] - 4s 557ms/step - loss: 29.0705 - val_loss: 21.9343\n",
      "Epoch 130/300\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 29.0205 - val_loss: 21.8798\n",
      "Epoch 131/300\n",
      "8/8 [==============================] - 5s 586ms/step - loss: 28.9747 - val_loss: 21.8257\n",
      "Epoch 132/300\n",
      "8/8 [==============================] - 4s 521ms/step - loss: 28.9106 - val_loss: 21.7717\n",
      "Epoch 133/300\n",
      "8/8 [==============================] - 4s 522ms/step - loss: 28.8548 - val_loss: 21.7177\n",
      "Epoch 134/300\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 28.8036 - val_loss: 21.6638\n",
      "Epoch 135/300\n",
      "8/8 [==============================] - 4s 555ms/step - loss: 28.7505 - val_loss: 21.6100\n",
      "Epoch 136/300\n",
      "8/8 [==============================] - 5s 600ms/step - loss: 28.7013 - val_loss: 21.5562\n",
      "Epoch 137/300\n",
      "8/8 [==============================] - 5s 588ms/step - loss: 28.6579 - val_loss: 21.5025\n",
      "Epoch 138/300\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 28.5809 - val_loss: 21.4485\n",
      "Epoch 139/300\n",
      "8/8 [==============================] - 5s 630ms/step - loss: 28.5401 - val_loss: 21.3948\n",
      "Epoch 140/300\n",
      "8/8 [==============================] - 5s 644ms/step - loss: 28.4774 - val_loss: 21.3410\n",
      "Epoch 141/300\n",
      "8/8 [==============================] - 5s 579ms/step - loss: 28.4281 - val_loss: 21.2873\n",
      "Epoch 142/300\n",
      "8/8 [==============================] - 7s 839ms/step - loss: 28.3710 - val_loss: 21.2335\n",
      "Epoch 143/300\n",
      "8/8 [==============================] - 6s 765ms/step - loss: 28.3236 - val_loss: 21.1798\n",
      "Epoch 144/300\n",
      "8/8 [==============================] - 5s 634ms/step - loss: 28.2742 - val_loss: 21.1261\n",
      "Epoch 145/300\n",
      "8/8 [==============================] - 6s 700ms/step - loss: 28.2045 - val_loss: 21.0725\n",
      "Epoch 146/300\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 28.1711 - val_loss: 21.0189\n",
      "Epoch 147/300\n",
      "8/8 [==============================] - 4s 556ms/step - loss: 28.0875 - val_loss: 20.9654\n",
      "Epoch 148/300\n",
      "8/8 [==============================] - 4s 560ms/step - loss: 28.0511 - val_loss: 20.9119\n",
      "Epoch 149/300\n",
      "8/8 [==============================] - 6s 717ms/step - loss: 27.9875 - val_loss: 20.8585\n",
      "Epoch 150/300\n",
      "8/8 [==============================] - 4s 544ms/step - loss: 27.9484 - val_loss: 20.8052\n",
      "Epoch 151/300\n",
      "8/8 [==============================] - 6s 714ms/step - loss: 27.8839 - val_loss: 20.7520\n",
      "Epoch 152/300\n",
      "8/8 [==============================] - 5s 618ms/step - loss: 27.8337 - val_loss: 20.6988\n",
      "Epoch 153/300\n",
      "8/8 [==============================] - 5s 638ms/step - loss: 27.7884 - val_loss: 20.6456\n",
      "Epoch 154/300\n",
      "8/8 [==============================] - 5s 582ms/step - loss: 27.7352 - val_loss: 20.5924\n",
      "Epoch 155/300\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 27.6640 - val_loss: 20.5393\n",
      "Epoch 156/300\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 27.6239 - val_loss: 20.4862\n",
      "Epoch 157/300\n",
      "8/8 [==============================] - 4s 490ms/step - loss: 27.5710 - val_loss: 20.4331\n",
      "Epoch 158/300\n",
      "8/8 [==============================] - 5s 600ms/step - loss: 27.5180 - val_loss: 20.3800\n",
      "Epoch 159/300\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 27.4615 - val_loss: 20.3270\n",
      "Epoch 160/300\n",
      "8/8 [==============================] - 5s 620ms/step - loss: 27.4083 - val_loss: 20.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 161/300\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 27.3518 - val_loss: 20.2210\n",
      "Epoch 162/300\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 27.2955 - val_loss: 20.1680\n",
      "Epoch 163/300\n",
      "8/8 [==============================] - 5s 643ms/step - loss: 27.2560 - val_loss: 20.1150\n",
      "Epoch 164/300\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 27.2027 - val_loss: 20.0621\n",
      "Epoch 165/300\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 27.1430 - val_loss: 20.0091\n",
      "Epoch 166/300\n",
      "8/8 [==============================] - 5s 624ms/step - loss: 27.0835 - val_loss: 19.9562\n",
      "Epoch 167/300\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 27.0437 - val_loss: 19.9033\n",
      "Epoch 168/300\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 26.9907 - val_loss: 19.8505\n",
      "Epoch 169/300\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 26.9344 - val_loss: 19.7976\n",
      "Epoch 170/300\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 26.8782 - val_loss: 19.7448\n",
      "Epoch 171/300\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 26.8290 - val_loss: 19.6920\n",
      "Epoch 172/300\n",
      "8/8 [==============================] - 5s 572ms/step - loss: 26.7788 - val_loss: 19.6392\n",
      "Epoch 173/300\n",
      "8/8 [==============================] - 5s 568ms/step - loss: 26.7233 - val_loss: 19.5864\n",
      "Epoch 174/300\n",
      "8/8 [==============================] - 5s 596ms/step - loss: 26.6763 - val_loss: 19.5337\n",
      "Epoch 175/300\n",
      "8/8 [==============================] - 5s 637ms/step - loss: 26.6145 - val_loss: 19.4809\n",
      "Epoch 176/300\n",
      "8/8 [==============================] - 5s 586ms/step - loss: 26.5705 - val_loss: 19.4282\n",
      "Epoch 177/300\n",
      "8/8 [==============================] - 4s 533ms/step - loss: 26.5116 - val_loss: 19.3755\n",
      "Epoch 178/300\n",
      "8/8 [==============================] - 4s 538ms/step - loss: 26.4493 - val_loss: 19.3228\n",
      "Epoch 179/300\n",
      "8/8 [==============================] - 4s 518ms/step - loss: 26.3968 - val_loss: 19.2702\n",
      "Epoch 180/300\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 26.3441 - val_loss: 19.2175\n",
      "Epoch 181/300\n",
      "8/8 [==============================] - 5s 641ms/step - loss: 26.2983 - val_loss: 19.1648\n",
      "Epoch 182/300\n",
      "8/8 [==============================] - 4s 561ms/step - loss: 26.2422 - val_loss: 19.1122\n",
      "Epoch 183/300\n",
      "8/8 [==============================] - 5s 586ms/step - loss: 26.1895 - val_loss: 19.0596\n",
      "Epoch 184/300\n",
      "8/8 [==============================] - 5s 582ms/step - loss: 26.1369 - val_loss: 19.0070\n",
      "Epoch 185/300\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 26.0843 - val_loss: 18.9544\n",
      "Epoch 186/300\n",
      "8/8 [==============================] - 5s 636ms/step - loss: 26.0379 - val_loss: 18.9018\n",
      "Epoch 187/300\n",
      "8/8 [==============================] - 5s 582ms/step - loss: 25.9721 - val_loss: 18.8492\n",
      "Epoch 188/300\n",
      "8/8 [==============================] - 5s 632ms/step - loss: 25.9225 - val_loss: 18.7967\n",
      "Epoch 189/300\n",
      "8/8 [==============================] - 5s 607ms/step - loss: 25.8731 - val_loss: 18.7441\n",
      "Epoch 190/300\n",
      "8/8 [==============================] - 5s 596ms/step - loss: 25.8278 - val_loss: 18.6916\n",
      "Epoch 191/300\n",
      "8/8 [==============================] - 5s 666ms/step - loss: 25.7743 - val_loss: 18.6391\n",
      "Epoch 192/300\n",
      "8/8 [==============================] - 5s 563ms/step - loss: 25.7122 - val_loss: 18.5866\n",
      "Epoch 193/300\n",
      "8/8 [==============================] - 5s 676ms/step - loss: 25.6686 - val_loss: 18.5341\n",
      "Epoch 194/300\n",
      "8/8 [==============================] - 5s 624ms/step - loss: 25.6122 - val_loss: 18.4816\n",
      "Epoch 195/300\n",
      "8/8 [==============================] - 6s 750ms/step - loss: 25.5544 - val_loss: 18.4291\n",
      "Epoch 196/300\n",
      "8/8 [==============================] - 5s 671ms/step - loss: 25.5088 - val_loss: 18.3766\n",
      "Epoch 197/300\n",
      "8/8 [==============================] - 5s 590ms/step - loss: 25.4586 - val_loss: 18.3242\n",
      "Epoch 198/300\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 25.4050 - val_loss: 18.2717\n",
      "Epoch 199/300\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 25.3516 - val_loss: 18.2193\n",
      "Epoch 200/300\n",
      "8/8 [==============================] - 5s 642ms/step - loss: 25.2882 - val_loss: 18.1669\n",
      "Epoch 201/300\n",
      "8/8 [==============================] - 6s 730ms/step - loss: 25.2492 - val_loss: 18.1145\n",
      "Epoch 202/300\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 25.2004 - val_loss: 18.0621\n",
      "Epoch 203/300\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 25.1398 - val_loss: 18.0097\n",
      "Epoch 204/300\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 25.0856 - val_loss: 17.9573\n",
      "Epoch 205/300\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 25.0384 - val_loss: 17.9049\n",
      "Epoch 206/300\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 24.9846 - val_loss: 17.8525\n",
      "Epoch 207/300\n",
      "8/8 [==============================] - 4s 540ms/step - loss: 24.9345 - val_loss: 17.8001\n",
      "Epoch 208/300\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 24.8822 - val_loss: 17.7477\n",
      "Epoch 209/300\n",
      "8/8 [==============================] - 4s 518ms/step - loss: 24.8246 - val_loss: 17.6953\n",
      "Epoch 210/300\n",
      "8/8 [==============================] - 4s 550ms/step - loss: 24.7749 - val_loss: 17.6429\n",
      "Epoch 211/300\n",
      "8/8 [==============================] - 4s 550ms/step - loss: 24.7276 - val_loss: 17.5905\n",
      "Epoch 212/300\n",
      "8/8 [==============================] - 5s 651ms/step - loss: 24.6653 - val_loss: 17.5381\n",
      "Epoch 213/300\n",
      "8/8 [==============================] - 5s 664ms/step - loss: 24.6078 - val_loss: 17.4856\n",
      "Epoch 214/300\n",
      "8/8 [==============================] - 5s 592ms/step - loss: 24.5689 - val_loss: 17.4331\n",
      "Epoch 215/300\n",
      "8/8 [==============================] - 5s 625ms/step - loss: 24.5164 - val_loss: 17.3805\n",
      "Epoch 216/300\n",
      "8/8 [==============================] - 5s 563ms/step - loss: 24.4615 - val_loss: 17.3278\n",
      "Epoch 217/300\n",
      "8/8 [==============================] - 6s 702ms/step - loss: 24.4100 - val_loss: 17.2749\n",
      "Epoch 218/300\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 24.3523 - val_loss: 17.2220\n",
      "Epoch 219/300\n",
      "8/8 [==============================] - 5s 620ms/step - loss: 24.3066 - val_loss: 17.1689\n",
      "Epoch 220/300\n",
      "8/8 [==============================] - 5s 632ms/step - loss: 24.2396 - val_loss: 17.1160\n",
      "Epoch 221/300\n",
      "8/8 [==============================] - 5s 606ms/step - loss: 24.1893 - val_loss: 17.0633\n",
      "Epoch 222/300\n",
      "8/8 [==============================] - 5s 612ms/step - loss: 24.1342 - val_loss: 17.0109\n",
      "Epoch 223/300\n",
      "8/8 [==============================] - 5s 583ms/step - loss: 24.0873 - val_loss: 16.9587\n",
      "Epoch 224/300\n",
      "8/8 [==============================] - 5s 615ms/step - loss: 24.0437 - val_loss: 16.9064\n",
      "Epoch 225/300\n",
      "8/8 [==============================] - 5s 649ms/step - loss: 23.9859 - val_loss: 16.8542\n",
      "Epoch 226/300\n",
      "8/8 [==============================] - 4s 559ms/step - loss: 23.9416 - val_loss: 16.8020\n",
      "Epoch 227/300\n",
      "8/8 [==============================] - 5s 602ms/step - loss: 23.8832 - val_loss: 16.7499\n",
      "Epoch 228/300\n",
      "8/8 [==============================] - 5s 569ms/step - loss: 23.8222 - val_loss: 16.6977\n",
      "Epoch 229/300\n",
      "8/8 [==============================] - 5s 589ms/step - loss: 23.7794 - val_loss: 16.6455\n",
      "Epoch 230/300\n",
      "8/8 [==============================] - 4s 542ms/step - loss: 23.7186 - val_loss: 16.5933\n",
      "Epoch 231/300\n",
      "8/8 [==============================] - 4s 529ms/step - loss: 23.6782 - val_loss: 16.5412\n",
      "Epoch 232/300\n",
      "8/8 [==============================] - 5s 565ms/step - loss: 23.6197 - val_loss: 16.4890\n",
      "Epoch 233/300\n",
      "8/8 [==============================] - 4s 538ms/step - loss: 23.5596 - val_loss: 16.4369\n",
      "Epoch 234/300\n",
      "8/8 [==============================] - 5s 600ms/step - loss: 23.5106 - val_loss: 16.3847\n",
      "Epoch 235/300\n",
      "8/8 [==============================] - 5s 608ms/step - loss: 23.4629 - val_loss: 16.3326\n",
      "Epoch 236/300\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 23.4187 - val_loss: 16.2805\n",
      "Epoch 237/300\n",
      "8/8 [==============================] - 5s 567ms/step - loss: 23.3597 - val_loss: 16.2284\n",
      "Epoch 238/300\n",
      "8/8 [==============================] - 4s 521ms/step - loss: 23.3032 - val_loss: 16.1763\n",
      "Epoch 239/300\n",
      "8/8 [==============================] - 5s 583ms/step - loss: 23.2576 - val_loss: 16.1241\n",
      "Epoch 240/300\n",
      "8/8 [==============================] - 4s 554ms/step - loss: 23.2056 - val_loss: 16.0721\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 241/300\n",
      "8/8 [==============================] - 4s 534ms/step - loss: 23.1502 - val_loss: 16.0200\n",
      "Epoch 242/300\n",
      "8/8 [==============================] - 4s 545ms/step - loss: 23.1022 - val_loss: 15.9679\n",
      "Epoch 243/300\n",
      "8/8 [==============================] - 5s 564ms/step - loss: 23.0490 - val_loss: 15.9158\n",
      "Epoch 244/300\n",
      "8/8 [==============================] - 4s 507ms/step - loss: 22.9883 - val_loss: 15.8637\n",
      "Epoch 245/300\n",
      "8/8 [==============================] - 5s 569ms/step - loss: 22.9483 - val_loss: 15.8117\n",
      "Epoch 246/300\n",
      "8/8 [==============================] - 5s 612ms/step - loss: 22.8884 - val_loss: 15.7596\n",
      "Epoch 247/300\n",
      "8/8 [==============================] - 4s 553ms/step - loss: 22.8419 - val_loss: 15.7076\n",
      "Epoch 248/300\n",
      "8/8 [==============================] - 4s 547ms/step - loss: 22.7876 - val_loss: 15.6555\n",
      "Epoch 249/300\n",
      "8/8 [==============================] - 5s 580ms/step - loss: 22.7344 - val_loss: 15.6035\n",
      "Epoch 250/300\n",
      "8/8 [==============================] - 5s 579ms/step - loss: 22.6830 - val_loss: 15.5514\n",
      "Epoch 251/300\n",
      "8/8 [==============================] - 5s 654ms/step - loss: 22.6224 - val_loss: 15.4994\n",
      "Epoch 252/300\n",
      "8/8 [==============================] - 5s 611ms/step - loss: 22.5728 - val_loss: 15.4474\n",
      "Epoch 253/300\n",
      "8/8 [==============================] - 5s 672ms/step - loss: 22.5294 - val_loss: 15.3954\n",
      "Epoch 254/300\n",
      "8/8 [==============================] - 6s 712ms/step - loss: 22.4720 - val_loss: 15.3434\n",
      "Epoch 255/300\n",
      "8/8 [==============================] - 6s 707ms/step - loss: 22.4186 - val_loss: 15.2914\n",
      "Epoch 256/300\n",
      "8/8 [==============================] - 5s 685ms/step - loss: 22.3777 - val_loss: 15.2394\n",
      "Epoch 257/300\n",
      "8/8 [==============================] - 5s 574ms/step - loss: 22.3112 - val_loss: 15.1874\n",
      "Epoch 258/300\n",
      "8/8 [==============================] - 5s 597ms/step - loss: 22.2627 - val_loss: 15.1354\n",
      "Epoch 259/300\n",
      "8/8 [==============================] - 6s 726ms/step - loss: 22.2148 - val_loss: 15.0834\n",
      "Epoch 260/300\n",
      "8/8 [==============================] - 6s 759ms/step - loss: 22.1600 - val_loss: 15.0314\n",
      "Epoch 261/300\n",
      "8/8 [==============================] - 5s 622ms/step - loss: 22.1120 - val_loss: 14.9794\n",
      "Epoch 262/300\n",
      "8/8 [==============================] - 5s 586ms/step - loss: 22.0636 - val_loss: 14.9275\n",
      "Epoch 263/300\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 22.0136 - val_loss: 14.8755\n",
      "Epoch 264/300\n",
      "8/8 [==============================] - 5s 571ms/step - loss: 21.9561 - val_loss: 14.8236\n",
      "Epoch 265/300\n",
      "8/8 [==============================] - 5s 591ms/step - loss: 21.9026 - val_loss: 14.7716\n",
      "Epoch 266/300\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 21.8541 - val_loss: 14.7197\n",
      "Epoch 267/300\n",
      "8/8 [==============================] - 5s 601ms/step - loss: 21.7962 - val_loss: 14.6677\n",
      "Epoch 268/300\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 21.7427 - val_loss: 14.6157\n",
      "Epoch 269/300\n",
      "8/8 [==============================] - 5s 584ms/step - loss: 21.6976 - val_loss: 14.5638\n",
      "Epoch 270/300\n",
      "8/8 [==============================] - 5s 595ms/step - loss: 21.6387 - val_loss: 14.5119\n",
      "Epoch 271/300\n",
      "8/8 [==============================] - 5s 662ms/step - loss: 21.5852 - val_loss: 14.4600\n",
      "Epoch 272/300\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 21.5383 - val_loss: 14.4080\n",
      "Epoch 273/300\n",
      "8/8 [==============================] - 5s 579ms/step - loss: 21.4810 - val_loss: 14.3561\n",
      "Epoch 274/300\n",
      "8/8 [==============================] - 5s 571ms/step - loss: 21.4275 - val_loss: 14.3042\n",
      "Epoch 275/300\n",
      "8/8 [==============================] - 5s 614ms/step - loss: 21.3825 - val_loss: 14.2523\n",
      "Epoch 276/300\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 21.3360 - val_loss: 14.2004\n",
      "Epoch 277/300\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 21.2772 - val_loss: 14.1485\n",
      "Epoch 278/300\n",
      "8/8 [==============================] - 4s 559ms/step - loss: 21.2233 - val_loss: 14.0967\n",
      "Epoch 279/300\n",
      "8/8 [==============================] - 5s 563ms/step - loss: 21.1695 - val_loss: 14.0448\n",
      "Epoch 280/300\n",
      "8/8 [==============================] - 5s 603ms/step - loss: 21.1214 - val_loss: 13.9929\n",
      "Epoch 281/300\n",
      "8/8 [==============================] - 5s 584ms/step - loss: 21.0638 - val_loss: 13.9410\n",
      "Epoch 282/300\n",
      "8/8 [==============================] - 5s 680ms/step - loss: 21.0266 - val_loss: 13.8891\n",
      "Epoch 283/300\n",
      "8/8 [==============================] - 5s 654ms/step - loss: 20.9655 - val_loss: 13.8373\n",
      "Epoch 284/300\n",
      "8/8 [==============================] - 5s 675ms/step - loss: 20.9136 - val_loss: 13.7854\n",
      "Epoch 285/300\n",
      "8/8 [==============================] - 5s 641ms/step - loss: 20.8581 - val_loss: 13.7336\n",
      "Epoch 286/300\n",
      "8/8 [==============================] - 5s 637ms/step - loss: 20.8064 - val_loss: 13.6817\n",
      "Epoch 287/300\n",
      "8/8 [==============================] - 5s 621ms/step - loss: 20.7544 - val_loss: 13.6299\n",
      "Epoch 288/300\n",
      "8/8 [==============================] - 4s 554ms/step - loss: 20.7061 - val_loss: 13.5780\n",
      "Epoch 289/300\n",
      "8/8 [==============================] - 4s 556ms/step - loss: 20.6506 - val_loss: 13.5262\n",
      "Epoch 290/300\n",
      "8/8 [==============================] - 5s 598ms/step - loss: 20.6006 - val_loss: 13.4743\n",
      "Epoch 291/300\n",
      "8/8 [==============================] - 5s 619ms/step - loss: 20.5468 - val_loss: 13.4225\n",
      "Epoch 292/300\n",
      "8/8 [==============================] - 5s 576ms/step - loss: 20.5116 - val_loss: 13.3707\n",
      "Epoch 293/300\n",
      "8/8 [==============================] - 5s 594ms/step - loss: 20.4523 - val_loss: 13.3189\n",
      "Epoch 294/300\n",
      "8/8 [==============================] - 5s 609ms/step - loss: 20.3950 - val_loss: 13.2670\n",
      "Epoch 295/300\n",
      "8/8 [==============================] - 5s 585ms/step - loss: 20.3432 - val_loss: 13.2152\n",
      "Epoch 296/300\n",
      "8/8 [==============================] - 5s 605ms/step - loss: 20.2950 - val_loss: 13.1634\n",
      "Epoch 297/300\n",
      "8/8 [==============================] - 5s 576ms/step - loss: 20.2376 - val_loss: 13.1116\n",
      "Epoch 298/300\n",
      "8/8 [==============================] - 5s 604ms/step - loss: 20.1914 - val_loss: 13.0598\n",
      "Epoch 299/300\n",
      "8/8 [==============================] - 5s 663ms/step - loss: 20.1396 - val_loss: 13.0080\n",
      "Epoch 300/300\n",
      "8/8 [==============================] - 5s 616ms/step - loss: 20.0822 - val_loss: 12.9562\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "\n",
    "sliced_T_enc = np.transpose(T[train_enc_start:train_enc_end,:])\n",
    "encoder_input_data = sliced_T_enc.reshape(sliced_T_enc.shape[0], sliced_T_enc.shape[1], 1)\n",
    "sliced_T_pred = np.transpose(T[train_pred_start:train_pred_end,:])\n",
    "decoder_target_data = sliced_T_pred.reshape(sliced_T_pred.shape[0], sliced_T_pred.shape[1], 1)\n",
    "\n",
    "\n",
    "# lagged target series for teacher forcing\n",
    "decoder_input_data = np.zeros(decoder_target_data.shape)\n",
    "decoder_input_data[:,1:,0] = decoder_target_data[:,:-1,0]\n",
    "decoder_input_data[:,0,0] = encoder_input_data[:,-1,0]\n",
    "\n",
    "\n",
    "model.compile(Adam(), loss='mean_absolute_error')\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data, epochs=epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7efee00ac050>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Mean Absolute Error Loss')\n",
    "plt.title('Loss Over Time')\n",
    "plt.legend(['Train','Valid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
